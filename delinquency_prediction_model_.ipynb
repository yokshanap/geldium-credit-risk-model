{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "lcKQO3G1z6Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files  # Use this only in Google Colab\n",
        "\n",
        "uploaded = files.upload()  # This will prompt you to upload a file\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the uploaded CSV file into a DataFrame\n",
        "# If you uploaded 'your_file.csv', change the filename accordingly\n",
        "df = pd.read_csv(next(iter(uploaded)))\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "a_huMUhz0PE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n"
      ],
      "metadata": {
        "id": "qdRTO6Pu0_m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where any of the selected features are missing\n",
        "df_cleaned = df[features + ['Delinquent_Account']].dropna()\n",
        "\n",
        "# Redefine features and target\n",
        "X = df_cleaned[features]\n",
        "y = df_cleaned['Delinquent_Account']\n"
      ],
      "metadata": {
        "id": "AGJFir6C1gP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Impute missing values with the mean of each column\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Proceed with train-test split on imputed data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "bjGHfMsV1jy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.impute import SimpleImputer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Load Data\n",
        "df = pd.read_csv(\"Geldium_Dataset.csv\")\n",
        "\n",
        "# Step 3: Feature Selection\n",
        "features = ['Income', 'Credit_Score', 'Credit_Utilization', 'Missed_Payments',\n",
        "            'Debt_to_Income_Ratio', 'Account_Tenure']\n",
        "X = df[features]\n",
        "y = df['Delinquent_Account']\n",
        "\n",
        "# Step 4: Impute Missing Values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Step 5: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 6: Train Model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 7: Predict & Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "# Step 8: Plot ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "plt.plot(fpr, tpr, label='Logistic Regression')\n",
        "plt.plot([0,1], [0,1], '--', color='gray')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dSspnPhy1oIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Step 1: Reuse your imputed data\n",
        "# (Assumes `X_imputed`, `y` already defined as in previous step)\n",
        "\n",
        "# Step 2: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 3: Train Random Forest Model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Predict\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "y_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Step 5: Evaluate\n",
        "print(\"Classification Report (Random Forest):\\n\", classification_report(y_test, y_pred_rf))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob_rf))\n",
        "\n",
        "# Step 6: Plot ROC Curve\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
        "plt.plot(fpr_rf, tpr_rf, label='Random Forest')\n",
        "plt.plot([0,1], [0,1], '--', color='gray')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve – Random Forest')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Rks89pjM13A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Get feature names (after dropping unneeded columns earlier)\n",
        "feature_names = X.columns\n",
        "\n",
        "# Step 2: Get importance values\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "# Step 3: Create DataFrame for visualization\n",
        "feat_imp_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Step 4: Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feat_imp_df.head(10))\n",
        "plt.title(\"Top 10 Important Features – Random Forest\")\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.tight_layout()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7wnq56zS1_Pu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}